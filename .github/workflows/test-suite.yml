name: Nexus Flow Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: false
        default: 'all'
        type: choice
        options:
        - all
        - unit
        - integration
        - e2e
        - performance
      coverage_threshold:
        description: 'Coverage threshold percentage'
        required: false
        default: '80'
        type: string

env:
  NODE_VERSION: '18'
  NEXUS_TEST_MODE: 'true'
  NEXUS_LOG_LEVEL: 'error'

jobs:
  # Job 1: Code Quality and Linting
  quality-check:
    name: Code Quality & Linting
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run ESLint
        run: npm run lint

      - name: Run TypeScript type check
        run: npm run typecheck

      - name: Run Prettier format check
        run: npx prettier --check "src/**/*.{ts,js,json}"

      - name: Check for security vulnerabilities
        run: npm audit --audit-level moderate

  # Job 2: Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: quality-check
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'unit' || github.event.inputs.test_type == ''
    strategy:
      matrix:
        node-version: ['18', '20']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js ${{ matrix.node-version }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run unit tests
        run: |
          npm run test -- --testMatch="**/unit/**/*.test.ts" --coverage --coverageReporters=lcov --coverageReporters=text-summary
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/unit

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-node-${{ matrix.node-version }}
          path: |
            test-results/unit/
            coverage/

      - name: Upload coverage to Codecov
        if: matrix.node-version == '18'
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          file: ./coverage/lcov.info
          flags: unit-tests
          name: nexus-flow-unit-coverage

  # Job 3: Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: quality-check
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'integration' || github.event.inputs.test_type == ''
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run integration tests
        run: |
          npm run test -- --testMatch="**/integration/**/*.test.ts" --testTimeout=60000 --coverage --coverageReporters=lcov
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/integration

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: |
            test-results/integration/
            coverage/

  # Job 4: End-to-End Tests
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: [quality-check, unit-tests]
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'e2e' || github.event.inputs.test_type == ''
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Setup test environment
        run: |
          mkdir -p tests/temp/e2e
          chmod 755 bin/nexus-flow.js

      - name: Run E2E tests
        run: |
          npm run test -- --testMatch="**/e2e/**/*.test.ts" --testTimeout=120000 --runInBand --coverage --coverageReporters=lcov
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/e2e
          CI: true

      - name: Upload E2E test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results-${{ matrix.os }}
          path: |
            test-results/e2e/
            coverage/
            tests/temp/e2e/

  # Job 5: Performance Tests
  performance-tests:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: quality-check
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == 'performance'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run performance tests
        run: |
          npm run test -- --testMatch="**/performance/**/*.test.ts" --testTimeout=300000 --runInBand
        env:
          JEST_JUNIT_OUTPUT_DIR: ./test-results/performance

      - name: Upload performance test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: performance-test-results
          path: |
            test-results/performance/

      - name: Generate performance report
        if: always()
        run: |
          echo "# Performance Benchmark Results" > performance-report.md
          echo "" >> performance-report.md
          echo "Performance tests completed at $(date)" >> performance-report.md
          echo "" >> performance-report.md
          if [ -f "test-results/performance/junit.xml" ]; then
            echo "See attached artifacts for detailed performance metrics." >> performance-report.md
          else
            echo "Performance tests did not generate detailed reports." >> performance-report.md
          fi

      - name: Comment performance results on PR
        if: github.event_name == 'pull_request' && always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            if (fs.existsSync('performance-report.md')) {
              const report = fs.readFileSync('performance-report.md', 'utf8');
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: report
              });
            }

  # Job 6: Cross-Platform Compatibility
  cross-platform-tests:
    name: Cross-Platform Tests
    runs-on: ${{ matrix.os }}
    needs: unit-tests
    if: github.event.inputs.test_type == 'all' || github.event.inputs.test_type == ''
    strategy:
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        node-version: ['18', '20']
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ matrix.node-version }}
          cache: 'npm'

      - name: Install dependencies
        run: |
          npm ci
          npm run build

      - name: Run core tests
        run: |
          npm run test -- --testMatch="**/unit/**/*.test.ts" --testPathIgnorePatterns="cli" --testTimeout=30000

      - name: Test CLI functionality (Unix)
        if: matrix.os != 'windows-latest'
        run: |
          chmod +x bin/nexus-flow.js
          node bin/nexus-flow.js --help

      - name: Test CLI functionality (Windows)
        if: matrix.os == 'windows-latest'
        run: |
          node bin/nexus-flow.js --help

  # Job 7: Security and Dependency Analysis
  security-analysis:
    name: Security Analysis
    runs-on: ubuntu-latest
    needs: quality-check
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run security audit
        run: |
          npm audit --audit-level high --production
          npm audit --audit-level moderate || true

      - name: Check for known vulnerabilities
        run: |
          npx audit-ci --config .audit-ci.json || true

      - name: Analyze dependencies
        run: |
          npx license-checker --onlyAllow 'MIT;Apache-2.0;ISC;BSD-2-Clause;BSD-3-Clause;CC0-1.0' || true

  # Job 8: Coverage Analysis and Reporting
  coverage-analysis:
    name: Coverage Analysis
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests]
    if: always() && (needs.unit-tests.result == 'success' || needs.integration-tests.result == 'success')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'

      - name: Download all test artifacts
        uses: actions/download-artifact@v4
        with:
          path: ./test-artifacts

      - name: Install dependencies
        run: npm ci

      - name: Merge coverage reports
        run: |
          mkdir -p merged-coverage
          npx nyc merge test-artifacts/*/coverage merged-coverage/coverage.json || true
          npx nyc report --temp-dir merged-coverage --reporter html --reporter lcov --report-dir final-coverage || true

      - name: Check coverage threshold
        run: |
          THRESHOLD=${{ github.event.inputs.coverage_threshold || '80' }}
          npx nyc check-coverage --temp-dir merged-coverage --lines $THRESHOLD --functions $THRESHOLD --branches $THRESHOLD --statements $THRESHOLD || {
            echo "Coverage below threshold of $THRESHOLD%"
            exit 1
          }

      - name: Upload final coverage report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: final-coverage-report
          path: |
            final-coverage/
            merged-coverage/

      - name: Upload to Codecov
        if: always()
        uses: codecov/codecov-action@v3
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          directory: final-coverage/
          flags: all-tests
          name: nexus-flow-complete-coverage

  # Job 9: Test Results Summary
  test-summary:
    name: Test Results Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, e2e-tests, performance-tests, cross-platform-tests, security-analysis, coverage-analysis]
    if: always()
    steps:
      - name: Generate test summary
        run: |
          echo "# Nexus Flow Test Suite Results" > test-summary.md
          echo "" >> test-summary.md
          echo "## Test Results Summary" >> test-summary.md
          echo "" >> test-summary.md
          echo "| Test Category | Status | Details |" >> test-summary.md
          echo "|---------------|--------|---------|" >> test-summary.md
          echo "| Unit Tests | ${{ needs.unit-tests.result }} | Core functionality testing |" >> test-summary.md
          echo "| Integration Tests | ${{ needs.integration-tests.result }} | Component integration testing |" >> test-summary.md
          echo "| E2E Tests | ${{ needs.e2e-tests.result }} | End-to-end workflow testing |" >> test-summary.md
          echo "| Performance Tests | ${{ needs.performance-tests.result }} | Performance benchmarking |" >> test-summary.md
          echo "| Cross-Platform Tests | ${{ needs.cross-platform-tests.result }} | Multi-platform compatibility |" >> test-summary.md
          echo "| Security Analysis | ${{ needs.security-analysis.result }} | Security and dependency analysis |" >> test-summary.md
          echo "| Coverage Analysis | ${{ needs.coverage-analysis.result }} | Code coverage validation |" >> test-summary.md
          echo "" >> test-summary.md
          echo "## Overall Status" >> test-summary.md
          echo "" >> test-summary.md
          if [[ "${{ needs.unit-tests.result }}" == "success" && "${{ needs.integration-tests.result }}" == "success" ]]; then
            echo "✅ Core test suite passed successfully!" >> test-summary.md
          else
            echo "❌ Core test suite failed. Please review the failed tests above." >> test-summary.md
          fi
          echo "" >> test-summary.md
          echo "Generated at: $(date)" >> test-summary.md

      - name: Upload test summary
        uses: actions/upload-artifact@v4
        with:
          name: test-summary
          path: test-summary.md

      - name: Comment test summary on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('test-summary.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

      - name: Set final status
        if: needs.unit-tests.result != 'success' || needs.integration-tests.result != 'success'
        run: |
          echo "Core tests failed"
          exit 1